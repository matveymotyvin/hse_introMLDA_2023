{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63537,"databundleVersionId":6957677,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:17:56.757334Z","iopub.execute_input":"2023-11-18T21:17:56.757713Z","iopub.status.idle":"2023-11-18T21:18:14.048344Z","shell.execute_reply.started":"2023-11-18T21:17:56.757682Z","shell.execute_reply":"2023-11-18T21:18:14.046834Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.8.8)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\nInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom scipy import sparse\nimport pandas as pd\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom sklearn.metrics import f1_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.tokenize.sonority_sequencing import SyllableTokenizer\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom tqdm import tqdm\nimport warnings\nSEED = 42","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T22:38:28.313372Z","iopub.execute_input":"2023-11-18T22:38:28.313814Z","iopub.status.idle":"2023-11-18T22:38:28.322279Z","shell.execute_reply.started":"2023-11-18T22:38:28.313778Z","shell.execute_reply":"2023-11-18T22:38:28.320976Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/intromlda-2023-1-porn-detection/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/intromlda-2023-1-porn-detection/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:14.235951Z","iopub.execute_input":"2023-11-18T21:18:14.236257Z","iopub.status.idle":"2023-11-18T21:18:15.970357Z","shell.execute_reply.started":"2023-11-18T21:18:14.236228Z","shell.execute_reply":"2023-11-18T21:18:15.969215Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Очистим данные от непонятных символов и букв не русского и английского алфавита.\n\nУдалим стопслова,а у url еще 'ru', 'com', 'www'. Заголовки обработаем стемингом, а url разобьем на слоги.","metadata":{}},{"cell_type":"code","source":"stemmer_eng = SnowballStemmer('english')\nstemmer_rus = SnowballStemmer('russian')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:15.973146Z","iopub.execute_input":"2023-11-18T21:18:15.974086Z","iopub.status.idle":"2023-11-18T21:18:15.979684Z","shell.execute_reply.started":"2023-11-18T21:18:15.974004Z","shell.execute_reply":"2023-11-18T21:18:15.978605Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocessor_title(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\" ,\" \", re.sub(r\"[^a-zа-яё]\", \" \", text))\n    tokens = []\n    for word in text.split(' '):\n        if (word in stopwords.words(['russian', 'english'])) or word=='':\n            continue\n        else: \n            tokens.append(word)\n            \n    for i in range (len(tokens)):\n        tokens[i] = stemmer_eng.stem(tokens[i])\n        tokens[i] = stemmer_rus.stem(tokens[i])\n        \n    return ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:15.981113Z","iopub.execute_input":"2023-11-18T21:18:15.981462Z","iopub.status.idle":"2023-11-18T21:18:15.993370Z","shell.execute_reply.started":"2023-11-18T21:18:15.981431Z","shell.execute_reply":"2023-11-18T21:18:15.992525Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"syllabletoken = SyllableTokenizer()\n\ndef process_url(url):\n    stop_ngram = ['ru', 'com', 'www', '', ' ']\n    \n    split = re.split('[^A-Za-z0-9]+', url)\n    tokens = [token for token in split if token not in stop_ngram]\n    \n    ngrams = []\n    for word in tokens:\n        ngrams += syllabletoken.tokenize(word)\n    \n    return ' '.join(ngrams)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:15.994897Z","iopub.execute_input":"2023-11-18T21:18:15.995210Z","iopub.status.idle":"2023-11-18T21:18:16.009312Z","shell.execute_reply.started":"2023-11-18T21:18:15.995183Z","shell.execute_reply":"2023-11-18T21:18:16.008178Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df[train_df.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:16.691996Z","iopub.execute_input":"2023-11-18T21:18:16.692407Z","iopub.status.idle":"2023-11-18T21:18:16.755831Z","shell.execute_reply.started":"2023-11-18T21:18:16.692371Z","shell.execute_reply":"2023-11-18T21:18:16.755017Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"          ID        url title  label\n78497  78497  jpg-1.com   NaN      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>url</th>\n      <th>title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>78497</th>\n      <td>78497</td>\n      <td>jpg-1.com</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:18.694104Z","iopub.execute_input":"2023-11-18T21:18:18.694486Z","iopub.status.idle":"2023-11-18T21:18:18.748972Z","shell.execute_reply.started":"2023-11-18T21:18:18.694456Z","shell.execute_reply":"2023-11-18T21:18:18.747856Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df['title_tokens'] = train_df['title'].apply(lambda x: preprocessor_title(x))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:18:32.434786Z","iopub.execute_input":"2023-11-18T21:18:32.435167Z","iopub.status.idle":"2023-11-18T21:26:38.420541Z","shell.execute_reply.started":"2023-11-18T21:18:32.435138Z","shell.execute_reply":"2023-11-18T21:26:38.419343Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df['url_token'] = train_df['url'].apply(lambda x: process_url(x))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:26:38.423152Z","iopub.execute_input":"2023-11-18T21:26:38.424084Z","iopub.status.idle":"2023-11-18T21:26:42.717254Z","shell.execute_reply.started":"2023-11-18T21:26:38.424040Z","shell.execute_reply":"2023-11-18T21:26:42.716309Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df.to_parquet('/kaggle/working/train_with_tokens.parquet')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:26:43.681684Z","iopub.execute_input":"2023-11-18T21:26:43.682009Z","iopub.status.idle":"2023-11-18T21:26:44.372382Z","shell.execute_reply.started":"2023-11-18T21:26:43.681981Z","shell.execute_reply":"2023-11-18T21:26:44.371333Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Попробуем LogisticRegression с разным векторайзерами","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer()\ncount_vectorizer = CountVectorizer()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:31:25.278238Z","iopub.execute_input":"2023-11-18T19:31:25.278647Z","iopub.status.idle":"2023-11-18T19:31:25.284000Z","shell.execute_reply.started":"2023-11-18T19:31:25.278616Z","shell.execute_reply":"2023-11-18T19:31:25.282976Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_train, df_test, y_train, y_test = train_test_split(train_df.drop('label', axis = 1), train_df.label, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:26:42.718473Z","iopub.execute_input":"2023-11-18T21:26:42.718836Z","iopub.status.idle":"2023-11-18T21:26:42.806577Z","shell.execute_reply.started":"2023-11-18T21:26:42.718806Z","shell.execute_reply":"2023-11-18T21:26:42.805450Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_train = df_train['url_token'].values + ' ' + df_train['title_tokens'].values\nX_test = df_test['url_token'].values + ' ' + df_test['title_tokens'].values","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:31:52.017059Z","iopub.execute_input":"2023-11-18T19:31:52.017479Z","iopub.status.idle":"2023-11-18T19:31:52.111062Z","shell.execute_reply.started":"2023-11-18T19:31:52.017449Z","shell.execute_reply":"2023-11-18T19:31:52.109946Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tfidf_vectorizer.fit(X_train)\ncount_vectorizer.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:32:03.045644Z","iopub.execute_input":"2023-11-18T19:32:03.046092Z","iopub.status.idle":"2023-11-18T19:32:08.051386Z","shell.execute_reply.started":"2023-11-18T19:32:03.046055Z","shell.execute_reply":"2023-11-18T19:32:08.050541Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"CountVectorizer()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"vect_train_tfidf = tfidf_vectorizer.transform(X_train)\nvect_train_count = count_vectorizer.transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T19:41:40.215416Z","iopub.execute_input":"2023-11-18T19:41:40.215876Z","iopub.status.idle":"2023-11-18T19:41:44.687913Z","shell.execute_reply.started":"2023-11-18T19:41:40.215823Z","shell.execute_reply":"2023-11-18T19:41:44.686701Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model_log_rec = LogisticRegression( C=1000, n_jobs= 4)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:16:13.903787Z","iopub.execute_input":"2023-11-18T20:16:13.904238Z","iopub.status.idle":"2023-11-18T20:16:13.909645Z","shell.execute_reply.started":"2023-11-18T20:16:13.904207Z","shell.execute_reply":"2023-11-18T20:16:13.908582Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model_log_rec.fit(vect_train_tfidf, y_train)\nprint('TfidfVectorizer train:', f1_score(y_train, model_log_rec.predict(vect_train_tfidf)))\nmodel_log_rec.fit(vect_train_count, y_train)\nprint('CountVectorizer train:', f1_score(y_train, model_log_rec.predict(vect_train_count)))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:16:40.527337Z","iopub.execute_input":"2023-11-18T20:16:40.527732Z","iopub.status.idle":"2023-11-18T20:16:47.799971Z","shell.execute_reply.started":"2023-11-18T20:16:40.527701Z","shell.execute_reply":"2023-11-18T20:16:47.798923Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"TfidfVectorizer train: 0.9995609308266475\nCountVectorizer train: 0.999600830273032\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}]},{"cell_type":"code","source":"vect_test_tfidf = tfidf_vectorizer.transform(X_test)\nvect_test_count = count_vectorizer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:16:55.415128Z","iopub.execute_input":"2023-11-18T20:16:55.415509Z","iopub.status.idle":"2023-11-18T20:16:56.955449Z","shell.execute_reply.started":"2023-11-18T20:16:55.415479Z","shell.execute_reply":"2023-11-18T20:16:56.954504Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model_log_rec.fit(vect_train_tfidf, y_train)\nprint('TfidfVectorizer test:', f1_score(y_test, model_log_rec.predict(vect_test_tfidf)))\nmodel_log_rec.fit(vect_train_count, y_train)\nprint('CountVectorizer test:', f1_score(y_test, model_log_rec.predict(vect_test_count)))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:16:59.295734Z","iopub.execute_input":"2023-11-18T20:16:59.296152Z","iopub.status.idle":"2023-11-18T20:17:06.838423Z","shell.execute_reply.started":"2023-11-18T20:16:59.296119Z","shell.execute_reply":"2023-11-18T20:17:06.837299Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"TfidfVectorizer test: 0.9742908871454435\nCountVectorizer test: 0.9737095996140858\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Попробуем LogisticRegressionCV с разным векторайзерами","metadata":{}},{"cell_type":"code","source":"preprocessor_cv = ColumnTransformer([\n    ('url_tokens', TfidfVectorizer(analyzer='word', dtype = np.float32), 'url_token'),\n    ('title_tokens', TfidfVectorizer(analyzer='word', dtype = np.float32), 'title_tokens'),   \n])\n\n    \n\n\nmodel_cv = Pipeline([\n    ('preprocessor', preprocessor_cv),\n    ('linear_model', LogisticRegressionCV(class_weight = 'balanced', cv = 3))\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:17:59.135420Z","iopub.execute_input":"2023-11-18T20:17:59.135797Z","iopub.status.idle":"2023-11-18T20:17:59.143293Z","shell.execute_reply.started":"2023-11-18T20:17:59.135768Z","shell.execute_reply":"2023-11-18T20:17:59.142145Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model_cv.fit(df_train, y_train)\npred_train = model_cv.predict(df_train)\npred_test = model_cv.predict(df_test)\nprint('LogisticRegressionCV train TfidfVectorizer f1_score: ', f1_score(pred_train, y_train))\nprint('LogisticRegressionCV test TfidfVectorizer f1_score: ', f1_score(pred_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:19:03.837031Z","iopub.execute_input":"2023-11-18T20:19:03.837427Z","iopub.status.idle":"2023-11-18T20:21:23.915936Z","shell.execute_reply.started":"2023-11-18T20:19:03.837398Z","shell.execute_reply":"2023-11-18T20:21:23.914802Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"LogisticRegressionCV train TfidfVectorizer f1_score:  0.9988436540531919\nLogisticRegressionCV test TfidfVectorizer f1_score:  0.974697205899988\n","output_type":"stream"}]},{"cell_type":"code","source":"model_cv.fit(df_train, y_train)\npred_train = model_cv.predict(df_train)\npred_test = model_cv.predict(df_test)\nprint('LogisticRegressionCV train CountVectorizer f1_score: ', f1_score(pred_train, y_train))\nprint('LogisticRegressionCV test CountVectorizer f1_score: ', f1_score(pred_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T20:18:49.996023Z","iopub.execute_input":"2023-11-18T20:18:49.996545Z","iopub.status.idle":"2023-11-18T20:18:50.056371Z","shell.execute_reply.started":"2023-11-18T20:18:49.996508Z","shell.execute_reply":"2023-11-18T20:18:50.055275Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"LogisticRegressionCV train CountVectorizerf1_score:  0.9992820103709613\nLogisticRegressionCV test CountVectorizer f1_score:  0.9760960960960962\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Попробуем сделать ансамбль моделей, лучше, но на лидерборде все равно не так хорошо","metadata":{}},{"cell_type":"code","source":"preprocessor1 = ColumnTransformer([\n    ('url_tokens', TfidfVectorizer(analyzer='word', dtype = np.float32), 'url_token'),\n    ('title_tokens', TfidfVectorizer(analyzer='word', dtype = np.float32), 'title_tokens'),   \n])\npreprocessor2 = ColumnTransformer([\n    ('url_tokens', TfidfVectorizer(analyzer='word', dtype = np.float32), 'url_token'),\n    ('title_tokens', TfidfVectorizer(analyzer='word', dtype = np.float32), 'title_tokens'),   \n])\npreprocessor3 = ColumnTransformer([\n    ('url_tokens', CountVectorizer(analyzer='word', dtype = np.float32), 'url_token'),\n    ('title_tokens', CountVectorizer(analyzer='word', dtype = np.float32), 'title_tokens'),   \n])\npreprocessor4 = ColumnTransformer([\n    ('url_tokens', CountVectorizer(analyzer='word', dtype = np.float32), 'url_token'),\n    ('title_tokens', CountVectorizer(analyzer='word', dtype = np.float32), 'title_tokens'),   \n])\n\n    \n\n\nmodel1 = Pipeline([\n    ('preprocessor', preprocessor1),\n    ('linear_model', LogisticRegressionCV(class_weight = 'balanced', cv = 3))\n])\nmodel2 = Pipeline([\n    ('preprocessor', preprocessor2),\n    ('linear_model', SGDClassifier(class_weight = 'balanced', loss='log_loss'))\n])\nmodel3 = Pipeline([\n    ('preprocessor', preprocessor3),\n    ('linear_model', LogisticRegression(class_weight = 'balanced'))\n])\nmodel4 = Pipeline([\n    ('preprocessor', preprocessor4),\n    ('linear_model', RandomForestClassifier(class_weight = 'balanced'))\n])\n\n\nensamble = VotingClassifier(estimators=[('mod1', model1), ('mod2', model2),\n                                     ('mod3', model3), ('mod4', model4)], voting = 'soft')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:38:09.671910Z","iopub.execute_input":"2023-11-18T21:38:09.672305Z","iopub.status.idle":"2023-11-18T21:38:09.686762Z","shell.execute_reply.started":"2023-11-18T21:38:09.672274Z","shell.execute_reply":"2023-11-18T21:38:09.685643Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"ensamble.fit(df_train, y_train)\npred_train = ensamble.predict(df_train)\npred_test = ensamble.predict(df_test)\nprint('Ensamble train f1_score: ', f1_score(pred_train, y_train))\nprint('Ensamble test f1_score: ', f1_score(pred_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:38:13.629540Z","iopub.execute_input":"2023-11-18T21:38:13.629936Z","iopub.status.idle":"2023-11-18T21:40:57.021818Z","shell.execute_reply.started":"2023-11-18T21:38:13.629902Z","shell.execute_reply":"2023-11-18T21:40:57.020588Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Ensamble train f1_score:  0.9948215423836838\nEnsamble test f1_score:  0.9752701080432173\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ансамбль тоже не показал себя сильно лучше. Скорее всего дела в фичах, надо пробовать делать новые. Найдем ключевые слова для заголовков и url","metadata":{}},{"cell_type":"code","source":"positive_texts_title = train_df.loc[train_df['label'] == 1, 'title_tokens'].tolist()\nnegative_texts_title = train_df.loc[train_df['label'] == 0, 'title_tokens'].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:46:05.429361Z","iopub.execute_input":"2023-11-18T21:46:05.429821Z","iopub.status.idle":"2023-11-18T21:46:05.462107Z","shell.execute_reply.started":"2023-11-18T21:46:05.429784Z","shell.execute_reply":"2023-11-18T21:46:05.460866Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"dictionary_pos = {}\nfor line in positive_texts_title:\n    line = line.strip()\n    for word in line.split():\n        if word in dictionary_pos.keys():\n            cur_value = dictionary_pos[word] + 1\n            dictionary_pos[word] = cur_value\n        else:\n            dictionary_pos[word] = 1\nsorted_dict_pos = [(k, dictionary_pos[k]) for k in sorted(dictionary_pos, key=dictionary_pos.get, reverse=True)]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:46:39.963731Z","iopub.execute_input":"2023-11-18T21:46:39.964114Z","iopub.status.idle":"2023-11-18T21:46:40.095983Z","shell.execute_reply.started":"2023-11-18T21:46:39.964083Z","shell.execute_reply":"2023-11-18T21:46:40.094799Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"dictionary_neg = {}\nfor line in negative_texts_title:\n    line = line.strip()\n    for word in line.split():\n        if word in dictionary_neg.keys():\n            cur_value = dictionary_neg[word] + 1\n            dictionary_neg[word] = cur_value\n        else:\n            dictionary_neg[word] = 1\nsorted_dict_neg = [(k, dictionary_neg[k]) for k in sorted(dictionary_neg, key=dictionary_neg.get, reverse=True)]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:48:14.527837Z","iopub.execute_input":"2023-11-18T21:48:14.528242Z","iopub.status.idle":"2023-11-18T21:48:15.439784Z","shell.execute_reply.started":"2023-11-18T21:48:14.528212Z","shell.execute_reply":"2023-11-18T21:48:15.438880Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"keys_only_in_pos = [key for key, num in sorted_dict_pos if key not in sorted_dict_neg]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:48:17.664290Z","iopub.execute_input":"2023-11-18T21:48:17.664699Z","iopub.status.idle":"2023-11-18T21:48:46.806619Z","shell.execute_reply.started":"2023-11-18T21:48:17.664658Z","shell.execute_reply":"2023-11-18T21:48:46.805440Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"keys_only_in_pos[:10]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:51:12.294439Z","iopub.execute_input":"2023-11-18T21:51:12.295488Z","iopub.status.idle":"2023-11-18T21:51:12.303349Z","shell.execute_reply.started":"2023-11-18T21:51:12.295433Z","shell.execute_reply":"2023-11-18T21:51:12.302142Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"['порн',\n 'porn',\n 'vide',\n 'виде',\n 'sex',\n 'онлайн',\n 'hd',\n 'секс',\n 'xxx',\n 'смотрет']"},"metadata":{}}]},{"cell_type":"markdown","source":"удалим элементы ссылок","metadata":{}},{"cell_type":"code","source":"keys_only_in_pos.remove('com')\nkeys_only_in_pos.remove('www')\nkeys_only_in_pos.remove('ru')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:51:10.105018Z","iopub.execute_input":"2023-11-18T21:51:10.105440Z","iopub.status.idle":"2023-11-18T21:51:10.110718Z","shell.execute_reply.started":"2023-11-18T21:51:10.105410Z","shell.execute_reply":"2023-11-18T21:51:10.109447Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"positive_texts_url = train_df.loc[train_df['label'] == 1, 'url_token'].tolist()\nnegative_texts_url = train_df.loc[train_df['label'] == 0, 'url_token'].tolist()\n\ndictionary_pos_url = {}\nfor line in positive_texts_url:\n    line = line.strip()\n    for word in line.split():\n        if word in dictionary_pos_url.keys():\n            cur_value = dictionary_pos_url[word] + 1\n            dictionary_pos_url[word] = cur_value\n        else:\n            dictionary_pos_url[word] = 1\nsorted_dict_pos_url = [(k, dictionary_pos_url[k]) for k in sorted(dictionary_pos_url, key=dictionary_pos_url.get, reverse=True)]\n\ndictionary_neg_url = {}\nfor line in negative_texts_url:\n    line = line.strip()\n    for word in line.split():\n        if word in dictionary_neg_url.keys():\n            cur_value = dictionary_neg_url[word] + 1\n            dictionary_neg_url[word] = cur_value\n        else:\n            dictionary_neg_url[word] = 1\nsorted_dict_neg_url = [(k, dictionary_neg_url[k]) for k in sorted(dictionary_neg_url, key=dictionary_neg_url.get, reverse=True)]\n\nkeys_only_in_pos_url = [key for key, num in sorted_dict_pos_url if key not in sorted_dict_neg_url]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:58:32.534865Z","iopub.execute_input":"2023-11-18T21:58:32.535221Z","iopub.status.idle":"2023-11-18T21:58:33.856818Z","shell.execute_reply.started":"2023-11-18T21:58:32.535191Z","shell.execute_reply":"2023-11-18T21:58:33.855818Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"keys_only_in_pos_url[:10]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T21:58:35.668101Z","iopub.execute_input":"2023-11-18T21:58:35.668683Z","iopub.status.idle":"2023-11-18T21:58:35.676612Z","shell.execute_reply.started":"2023-11-18T21:58:35.668615Z","shell.execute_reply":"2023-11-18T21:58:35.675523Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"['por', 'no', 'net', 'porn', 'bi', 'org', 'tu', 'me', 'mo', 'be']"},"metadata":{}}]},{"cell_type":"markdown","source":"отдельно выделим русские и английские, русские будем использовать больше","metadata":{}},{"cell_type":"code","source":"russian_word_pattern = re.compile(r'^[а-я]+$')\nrussian_words = [key for key in keys_only_in_pos if russian_word_pattern.match(key)]\nenglish_word_pattern = re.compile(r'^[a-z]+$')\nenglish_words = [key for key in keys_only_in_pos if english_word_pattern.match(key)]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:05:29.283848Z","iopub.execute_input":"2023-11-18T22:05:29.284279Z","iopub.status.idle":"2023-11-18T22:05:29.310271Z","shell.execute_reply.started":"2023-11-18T22:05:29.284246Z","shell.execute_reply":"2023-11-18T22:05:29.309001Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"создадим функцию для создания матрицы фич","metadata":{}},{"cell_type":"code","source":"def features(df):    \n    title = df[\"title\"].values\n    url = df[\"url\"].values\n    result = []\n    for i, val in enumerate(title):\n        result.append([])\n        for j in russian_words[:800]:\n            result[-1].append(int(j in val.lower()))\n        for j in english_words[:200]:\n            result[-1].append(int(j in val.lower()))\n        for j in keys_only_in_pos_url[:200]:\n            result[-1].append(int(j in url[i].lower()))\n    return result\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegressionCV ","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:05:35.093779Z","iopub.execute_input":"2023-11-18T22:05:35.094176Z","iopub.status.idle":"2023-11-18T22:05:35.102993Z","shell.execute_reply.started":"2023-11-18T22:05:35.094145Z","shell.execute_reply":"2023-11-18T22:05:35.101810Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# df_train, df_test, y_train, y_test = train_test_split(train_df.drop('label', axis = 1), train_df.label, random_state=SEED)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train[\"title\"].values + ' ' + df_train[\"url\"].values\nX_test = df_test[\"title\"].values+ ' '+df_test[\"url\"].values","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:04:58.493453Z","iopub.execute_input":"2023-11-18T22:04:58.493844Z","iopub.status.idle":"2023-11-18T22:04:58.590929Z","shell.execute_reply.started":"2023-11-18T22:04:58.493815Z","shell.execute_reply":"2023-11-18T22:04:58.590048Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX_train_vectorized = sparse.hstack((vectorizer.fit_transform(X_train), sparse.csr_matrix(np.asarray(features(df_train)))))\n\nmodel =  LinearSVC(class_weight='balanced')\nmodel.fit(\n    X_train_vectorized,\n    y_train\n)\ny_pred = model.predict(\n    X_train_vectorized\n)\nprint(f1_score(y_train, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:06:42.340791Z","iopub.execute_input":"2023-11-18T22:06:42.341215Z","iopub.status.idle":"2023-11-18T22:09:35.589249Z","shell.execute_reply.started":"2023-11-18T22:06:42.341181Z","shell.execute_reply":"2023-11-18T22:09:35.588103Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"0.999680817108203\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test_vectorized = sparse.hstack((vectorizer.transform(X_test), sparse.csr_matrix(np.asarray(features(df_test)))))\ny_pred_test = model.predict(\n    X_test_vectorized\n)\nprint(f1_score(y_test, y_pred_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:12:28.060887Z","iopub.execute_input":"2023-11-18T22:12:28.061348Z","iopub.status.idle":"2023-11-18T22:12:28.086319Z","shell.execute_reply.started":"2023-11-18T22:12:28.061313Z","shell.execute_reply":"2023-11-18T22:12:28.085400Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"0.9823083403538332\n","output_type":"stream"}]},{"cell_type":"markdown","source":"как вижно эта модель показывает значительных прирост, если поиграться с количеством ключевых слов. Но слишком много использовать не получается так как сильно увеличивается время","metadata":{}},{"cell_type":"code","source":"X_train = train_df[\"title\"].values + ' ' + train_df[\"url\"].values\nX_test = test_df[\"title\"].values+ ' '+test_df[\"url\"].values\ny_train = train_df[\"label\"].astype(int).values","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:15:32.061643Z","iopub.execute_input":"2023-11-18T22:15:32.062147Z","iopub.status.idle":"2023-11-18T22:15:32.267032Z","shell.execute_reply.started":"2023-11-18T22:15:32.062107Z","shell.execute_reply":"2023-11-18T22:15:32.265819Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX_train_vectorized = sparse.hstack((vectorizer.fit_transform(X_train), sparse.csr_matrix(np.asarray(features(train_df)))))\n\nmodel =  LinearSVC(class_weight='balanced')\nmodel.fit(\n    X_train_vectorized,\n    y_train\n)\ny_pred = model.predict(\n    X_train_vectorized\n)\nprint(f1_score(y_train, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:15:37.348797Z","iopub.execute_input":"2023-11-18T22:15:37.349185Z","iopub.status.idle":"2023-11-18T22:19:26.723834Z","shell.execute_reply.started":"2023-11-18T22:15:37.349156Z","shell.execute_reply":"2023-11-18T22:19:26.722661Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"0.999611255644269\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Это оказался самый лучший подход, были различные эксперименты с количеством ключевых слов russian_words[:800], так как при большом значение матрица создается долго, но при этом увеличивается точность. Также были различные эксперименты с моделями (LinearSVC, RandomForestClassifier, SGDClassifier, LogisticRegression, LogisticRegressionCV), но LinearSVC, показала лучший результат на лидерборде с параметрами по умолчанию.\n\nТакже я пробовал обучить ансамбль на этих данных, но он слишком долго учится и результаты почему-то лучше не получились.","metadata":{}},{"cell_type":"markdown","source":"Также проанализиров данные, можно сделать предположения что дополнительно можно проверять не был ли этот сайт замечен с запрещенным контентом в трейне, а также нет ли в заголовке слов, которые, очевидно, говорят, о запрещенном контентом.","metadata":{}},{"cell_type":"code","source":"X_test_vectorized = sparse.hstack((vectorizer.transform(X_test), sparse.csr_matrix(np.asarray(features(test_df)))))\n\ntest_df[\"label\"] = model.predict(X_test_vectorized).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:20:43.908798Z","iopub.execute_input":"2023-11-18T22:20:43.909844Z","iopub.status.idle":"2023-11-18T22:25:19.506376Z","shell.execute_reply.started":"2023-11-18T22:20:43.909801Z","shell.execute_reply":"2023-11-18T22:25:19.505068Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:25:30.861126Z","iopub.execute_input":"2023-11-18T22:25:30.861591Z","iopub.status.idle":"2023-11-18T22:25:30.875787Z","shell.execute_reply.started":"2023-11-18T22:25:30.861544Z","shell.execute_reply":"2023-11-18T22:25:30.874492Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"       ID                url  \\\n0  135309  www.kommersant.ru   \n1  135310    urexpert.online   \n2  135311      imperimeha.ru   \n3  135312  national-porn.com   \n4  135313            2gis.ru   \n\n                                               title  label  \n0  Шестой кассационный суд в Самаре начнет работу...      0  \n1  Что такое индексация алиментов, кем и в каких ...      0  \n2                  Женщинам | Империя Меха - Part 12      0  \n3  Небритые, волосатые киски: Порно всех стран и ...      1  \n4                                                 67      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>url</th>\n      <th>title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>135309</td>\n      <td>www.kommersant.ru</td>\n      <td>Шестой кассационный суд в Самаре начнет работу...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>135310</td>\n      <td>urexpert.online</td>\n      <td>Что такое индексация алиментов, кем и в каких ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>135311</td>\n      <td>imperimeha.ru</td>\n      <td>Женщинам | Империя Меха - Part 12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>135312</td>\n      <td>national-porn.com</td>\n      <td>Небритые, волосатые киски: Порно всех стран и ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>135313</td>\n      <td>2gis.ru</td>\n      <td>67</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Создадим список с запрещенными сайтами, для этого возьмем те сайты, которые были замечены с запрещенным контентов в трейне более 2 раз. Пробовал более 1, но это ухудшало результат на лидерборде.","metadata":{}},{"cell_type":"code","source":"prohibited_sites = []\nfor url in train_df.groupby('url'):\n    if ( url[1].label.count() > 2 ):\n        if ( all(url[1].label) ):\n            prohibited_sites.append(url[0])\nprint(len(prohibited_sites))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:25:51.856808Z","iopub.execute_input":"2023-11-18T22:25:51.857200Z","iopub.status.idle":"2023-11-18T22:25:56.581586Z","shell.execute_reply.started":"2023-11-18T22:25:51.857169Z","shell.execute_reply":"2023-11-18T22:25:56.580481Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"951\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Также дополнительно будем проверять нет ли в заголовках или url, ключевых самых популярных запрещенных слов","metadata":{}},{"cell_type":"code","source":"test_df['label'] = test_df.apply(lambda x:  int(x['label'] or \n                                            ('porn' in x['url']) or\n                                            ('xxx' in x['url']) or\n                                            ('xvideo' in x['url']) or (' порно ' in x['title'].lower()) or ('porn' in x['title'].lower()) or (x['url'] in prohibited_sites)), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:26:22.655084Z","iopub.execute_input":"2023-11-18T22:26:22.655492Z","iopub.status.idle":"2023-11-18T22:26:31.490749Z","shell.execute_reply.started":"2023-11-18T22:26:22.655460Z","shell.execute_reply":"2023-11-18T22:26:31.489811Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"test_df[[\"ID\", \"label\"]].to_csv(\"/kaggle/working/solution.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:26:34.817504Z","iopub.execute_input":"2023-11-18T22:26:34.817928Z","iopub.status.idle":"2023-11-18T22:26:35.226338Z","shell.execute_reply.started":"2023-11-18T22:26:34.817895Z","shell.execute_reply":"2023-11-18T22:26:35.225079Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"По итогу удалось обучить относительно хорошую модель не применяя сложных преобразований, энкодеров и других сложных моделей трубующих gpu.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}